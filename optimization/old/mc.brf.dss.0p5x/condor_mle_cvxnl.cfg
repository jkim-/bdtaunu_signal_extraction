[job_config]

# Optimizer and parallelization configuration
# ===========================================

# number of nodes to use
nodes = 200

# number of bag iterations per node
bags = 6

# additional overall scale to apply to the objective function
obj_scale = 1e-8


# Path configuration
# ==================

# absolute path to mle_cvx.py. NOT the symlink! 
#exec_dir = /home/dchao/workspace/bdtaunu_signal_extraction/optimization
exec_dir = /home/jkim/Analysis/bdtaunu_signal_extraction/optimization

# absolute path to the directory containing the cached input files
#cached_input_dir = /home/dchao/workspace/bdtaunu_signal_extraction/optimization/mc.default
cached_input_dir = /home/jkim/Analysis/bdtaunu_signal_extraction/optimization/mc.brf.dss.0p5x

# cached densities file name
cached_densities_fname = cached_densities_evaluations.csv

# cached weights file name
cached_weights_fname = cached_weights.csv

# abolute path to the directory to create the output directory
output_dir = /home/jkim/Analysis/bdtaunu_signal_extraction/optimization/mc.brf.dss.0p5x

# directory name containing the result
output_dirname = condor_mle_cvxnl_output

# Queue configuration
# ===================

# user name
user_name = jkim

# user group
user_group = group_babar

# memory request to condor
request_memory = 1800
